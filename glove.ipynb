{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LIB_DIR = '~/kcpark/package/tensorflow-glove'\n",
    "WORK_DIR = '~/kcpark/workspace/dl4rs/embedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(LIB_DIR)\n",
    "import tf_glove\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = tf_glove.GloVeModel(\n",
    "    embedding_size=100,    # 50-300\n",
    "    context_size=10,\n",
    "    max_vocab_size=100000,\n",
    "    min_occurrences=5,\n",
    "    batch_size=512,\n",
    "    learning_rate=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "def get_corpus(corpus_file):\n",
    "    for l in open(corpus_file):\n",
    "        gdid, terms = l.strip().split('\\t')\n",
    "        yield eval(terms)\n",
    "corpus = get_corpus(WORK_DIR + '/data/gdid_terms.txt')\n",
    "model.fit_to_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train\n",
    "model.train(\n",
    "    log_dir=WORK_DIR+'/logs',\n",
    "    num_epochs=100,\n",
    "    summary_batch_interval=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save result\n",
    "np.save(WORK_DIR+'/model/terms-ep100', model.embeddings)\n",
    "with open(WORK_DIR+'/model/topic/vocab.txt', 'w') as vocab:\n",
    "    vocab.write('\\n'.join(model.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박 0.179967367811\n",
      "최순실 0.20153814522\n",
      "대통령 0.210056379461\n",
      "박근혜대통령 0.215602902534\n",
      "haya 0.262342389569\n",
      "언급 0.27083923758\n",
      "jtbc 0.289942448603\n",
      "농단 0.295315069633\n",
      "비판 0.302289370393\n",
      "최도원 0.308392517171\n"
     ]
    }
   ],
   "source": [
    "# nn\n",
    "from scipy.spatial.distance import cdist\n",
    "v = model.embedding_for('박근혜')    # model.embedding[model.id_for_word('박근혜')]\n",
    "W = model.embeddings\n",
    "similarity = cdist(W, v.reshape(1, -1), 'cosine').reshape(-1)\n",
    "for idx in similarity.argsort()[1:10+1]:\n",
    "    print model.words[idx], similarity[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
